/*
 * Copyright (C) 2018 MIPS Tech, LLC
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the MIPS Technologies, Inc., nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY IMAGINATION TECHNOLOGIES LIMITED ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED. IN NO EVENT SHALL IMAGINATION TECHNOLOGIES LIMITED BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */

#ifdef ANDROID_CHANGES
# include "machine/asm.h"
# include "machine/regdef.h"
#elif _LIBC
# include <sysdep.h>
# include <regdef.h>
# include <sys/asm.h>
#elif _COMPILING_NEWLIB
# include "machine/asm.h"
# include "machine/regdef.h"
#else
# include <regdef.h>
# include <sys/asm.h>
#endif

/* Testing on a little endian machine showed using CLZ was a
   performance loss, so we are not turning it on by default.  */
#if !defined(__nanomips_subset) && defined(ENABLE_CLZ) && (__mips_isa_rev > 1)
# define USE_CLZ
#else
/* Using ALIGN when EXT is unavailable.  */
# if defined(__nanomips_subset) || defined(DISABLE_EXT)
#  define USE_ALIGN_INST
# endif
#endif

/* Some asm.h files do not have the L macro definition.  */
#ifndef L
# if _MIPS_SIM == _ABIO32
#  define L(label) $L ## label
# else
#  define L(label) .L ## label
# endif
#endif

/* Some asm.h files do not have the PTR_ADDIU macro definition.  */
#ifndef PTR_ADDIU
# ifdef USE_DOUBLE
#  define PTR_ADDIU       daddiu
# else
#  define PTR_ADDIU       addiu
# endif
#endif

/* Allow the routine to be named something else if desired.  */
#ifndef STRCMP_NAME
# define STRCMP_NAME strcmp
#endif
	.align 2
#ifdef ANDROID_CHANGES
LEAF(STRCMP_NAME, 0)
#else
LEAF(STRCMP_NAME)
#endif
	.set	nomips16

	or	t0, a0, a1
	andi	t0, t0, 0x3
	bne	t0, zero, L(byteloop)

/* Both strings are 4 byte aligned at this point.  */

	li	t8, 0x01010101
#if !defined(__mips_dsp)
	li	t9, 0x7f7f7f7f
#endif

#ifdef __mips_dsp
# define STRCMP32(OFFSET) \
	lw	a2, OFFSET(a0); \
	lw	a3, OFFSET(a1); \
	subu_s.qb t0, t8, a2; \
	bne	a2, a3, L(worddiff); \
	bne	t0, zero, L(returnzero)
#else  /* !__mips_dsp */
# define STRCMP32(OFFSET) \
	lw	a2, OFFSET(a0); \
	lw	a3, OFFSET(a1); \
	subu	t0, a2, t8; \
	nor	t1, a2, t9; \
	and	t1, t0, t1; \
	bne	a2, a3, L(worddiff); \
	bne	t1, zero, L(returnzero)
#endif /* __mips_dsp */
L(wordloop):
	STRCMP32(0)
	STRCMP32(4)
	STRCMP32(8)
	STRCMP32(12)
	STRCMP32(16)
	STRCMP32(20)
	STRCMP32(24)
	lw	a2, 28(a0)
	lw	a3, 28(a1)
#ifndef __mips_dsp
	subu	t0, a2, t8
	nor	t1, a2, t9
#else
	subu_s.qb t0, t8, a2
#endif
#ifndef __mips_dsp
	and	t1, t0, t1
#endif
	bnec	a2, a3, L(worddiff)
	PTR_ADDIU a0, a0, 32
	bne	t1, zero, L(returnzero)
	PTR_ADDIU a1, a1, 32
	b	L(wordloop)

L(returnzero):
	move	va0, zero
	jr	ra

L(worddiff):
#ifdef USE_CLZ
	xor	t0, a2, a3
	or	t0, t0, t1
# if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
#  if defined(__nanomips__) && !defined(__nanomips_subset)
	byterevw t0, t0
#  else /* ! __nanomips__ */
	wsbh	t0, t0
	rotr	t0, t0, 16
#  endif /* __nanomips__ */
# endif /* LITTLE_ENDIAN */
	clz	t1, t0
	or	t0, t1, 24	/* Only care about multiples of 8.  */
	xor 	t1, t1, t0	/* {0,8,16,24} => {24,16,8,0}  */
# if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
	sllv	a2,a2,t1
	sllv	a3,a3,t1
#else
	srlv	a2,a2,t1
	srlv	a3,a3,t1
#endif
	subu	va0, a2, a3
	jr	ra
#else /* USE_CLZ */
# if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
	andi	a0, a2, 0xff	/* abcd => d */
	andi	a1, a3, 0xff
	beq	a0, zero, L(wexit01)
	bne	a0, a1, L(wexit01)

#  ifdef USE_ALIGN_INST
	align	t0, a2, a2, 2 	/* abcd => cdab */
	align	t1, a3, a3, 2
	srl	a0, t0, 24 	/* cdab => c */
	srl	a1, t1, 24
	beq	a0, zero, L(wexit01)
	bne	a0, a1, L(wexit01)
	andi	a0, t0, 0xff	/* cdab => b */
	andi	a1, t1, 0xff
#  else  /* !USE_ALIGN_INST */
	ext	a0, a2, 8, 8
	ext	a1, a3, 8, 8
	beq	a0, zero, L(wexit01)
	bne	a0, a1, L(wexit01)

	ext	a0, a2, 16, 8
	ext	a1, a3, 16, 8
#  endif  /* !USE_ALIGN_INST */

# else /* __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__ */
	srl	a0, a2, 24	/* abcd => a */
	srl	a1, a3, 24
	beq	a0, zero, L(wexit01)
	bne	a0, a1, L(wexit01)

#  ifdef USE_ALIGN_INST
	align	t0, a2, a2, 2 	/* abcd => cdab */
	align	t1, a3, a3, 2
	andi	a0, t0, 0xff 	/* cdab => b */
	andi	a1, t1, 0xff
	beq	a0, zero, L(wexit01)
	bne	a0, a1, L(wexit01)
	srl	a0, t0, 24	/* cdab => c */
	srl	a1, t1, 24
#  else /* ! USE_ALIGN_INST */
	ext	a0, a2, 16, 8
	ext	a1, a3, 16, 8
	beq	a0, zero, L(wexit01)
	bne	a0, a1, L(wexit01)
	ext	a0, a2, 8, 8
	ext	a1, a3, 8, 8
#  endif  /* USE_ALIGN_INST */

# endif /* __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__ */

	beq	a0, zero, L(wexit01)
	bne	a0, a1, L(wexit01)

	/* The other bytes are identical, so just subract the 2 words
	  and return the difference.  */
# if defined(__nanomips__) && !defined(__nanomips_subset)
	movep a0,a1,a2,a3
# else
	move a0, a2
	move a1, a3
# endif

L(wexit01):
	subu	va0, a0, a1
	jr	ra
#endif /* USE_CLZ */

#define BYTECMP01(OFFSET) \
	lbu	a3, OFFSET(a1); \
	beq	a2, zero, L(bexit01); \
	lbu	t8, OFFSET+1(a0); \
	bne	a2, a3, L(bexit01)

#define BYTECMP89(OFFSET) \
	lbu	t9, OFFSET(a1); \
	beq	t8, zero, L(bexit89); \
	lbu	a2, OFFSET+1(a0); \
	bne	t8, t9, L(bexit89)

L(byteloop):
	lbu	a2, 0(a0)
	BYTECMP01(0)
	BYTECMP89(1)
	BYTECMP01(2)
	BYTECMP89(3)
	BYTECMP01(4)
	BYTECMP89(5)
	BYTECMP01(6)
	lbu	t9, 7(a1)
	beq	t8, zero, L(bexit89)
	PTR_ADDIU a0, a0, 8
	bne	t8, t9, L(bexit89)
	PTR_ADDIU a1, a1, 8
	b	L(byteloop)

L(bexit01):
	subu	va0, a2, a3
	jr	ra
L(bexit89):
	subu	va0, t8, t9
	jr	ra

	.set	at

END(STRCMP_NAME)
#ifndef ANDROID_CHANGES
# ifdef _LIBC
libc_hidden_builtin_def (STRCMP_NAME)
# endif
#endif
